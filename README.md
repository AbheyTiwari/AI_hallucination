# ğŸ§  AI Hallucination Risk Prediction â€” Notebook

This Jupyter Notebook presents the **backend model and analysis** for predicting AI hallucinations, using a mathematical framework that factors in:

- **Data Quality**
- **Model Confidence**
- **Input Ambiguity**
- **Adversarial Strength**

It complements the interactive [AI Hallucination Prediction Dashboard](./index.html), which visually demonstrates the same logic in real time.

---

## ğŸ“˜ About This Notebook

The notebook includes:

- ğŸ“Š **Exploratory Data Analysis (EDA)** on synthetic or collected samples  
- ğŸ§® **Mathematical formulation** of hallucination risk  
- ğŸ” **Feature engineering** (Z-score, interaction terms, normalization)  
- ğŸ“ˆ **Model training and evaluation** (e.g., logistic regression, GLMM)  
- ğŸ¯ **Feature importance analysis** (using SHAP or coefficients)  
- âœ… **Performance metrics**: Accuracy, ROC-AUC, F1-Score  

---

## ğŸ§ª Mathematical Model

We define the hallucination risk `H` as:

H = Ïƒ(Î±D + Î²M + Î³I + Î´A + Î·C + Î¸(DÂ·M) + Ï†(IÂ·A) + Îµ)

Where:

- `Ïƒ` = Sigmoid function  
- `D` = Data Quality  
- `M` = Model Confidence  
- `I` = Input Ambiguity  
- `A` = Adversarial Strength  
- `Îµ` = Random noise / model bias  
- Interaction terms (`DÂ·M`, `IÂ·A`) capture non-linear dependencies

---

## ğŸ“‚ Files in This Repository

| File | Description |
|------|-------------|
| `hallucination_model.ipynb` | ğŸ§  The core analysis and modeling notebook |
| `index.html` | ğŸ¨ Interactive dashboard visualizing the same model |
| `README.md` | ğŸ“˜ You're here |

---

## ğŸ“ˆ Model Summary

| Metric      | Value   |
|-------------|---------|
| Accuracy    | 94.2%   |
| ROC-AUC     | 0.91    |
| F1 Score    | 0.89    |
| Samples     | 200     |

---

## ğŸš€ How to Run

### Requirements

- Python 3.8+
- Jupyter Notebook or JupyterLab
- `numpy`, `pandas`, `scikit-learn`, `matplotlib`, `seaborn`, `shap`

### Run with:

```bash
jupyter notebook AI_hallucination.ipynb
